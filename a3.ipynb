{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data \n",
    "IMDB_train = pd.read_csv('IMDB-train copy.txt',sep = '\\t',header = None)\n",
    "yelp_train = pd.read_csv('yelp-train copy.txt',sep = '\\t',header = None)\n",
    "\n",
    "# validation data\n",
    "IMDB_valid = pd.read_csv('IMDB-valid copy.txt',sep = '\\t',header = None)\n",
    "yelp_valid = pd.read_csv('yelp-valid copy.txt',sep = '\\t',header = None)\n",
    "\n",
    "# test data\n",
    "IMDB_test = pd.read_csv('IMDB-test copy.txt',sep = '\\t',header = None)\n",
    "yelp_test = pd.read_csv('yelp-test copy.txt',sep = '\\t',header = None)\n",
    "\n",
    "# vocab\n",
    "IMDB_vocab = pd.read_csv('IMDB-vocab copy.txt',sep = '\\t',header = None)\n",
    "yelp_vocab = pd.read_csv('yelp-vocab copy.txt',sep = '\\t',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing into bag of words and frequency of words \n",
    "def preprocessing_bow(data): \n",
    "    binary = np.zeros((len(data),10000))\n",
    "    for i in range(len(data[0])):\n",
    "        review = data.iloc[i,0].split(' ')\n",
    "        for j in range(len(review)): \n",
    "            try:\n",
    "                review[j]=int(review[j])\n",
    "                binary[i][review[j]]=1\n",
    "            except: \n",
    "                continue\n",
    "    return binary\n",
    "\n",
    "def preprocessing_fbow(data):\n",
    "    frequency = np.zeros((len(data),10000))\n",
    "    for i in range(len(data[0])):\n",
    "        review = data.iloc[i,0].split(' ')\n",
    "        for j in range(len(review)):\n",
    "            try:\n",
    "                review[j]=int(review[j])\n",
    "                frequency[i][review[j]] += 1/len(review)\n",
    "            except:\n",
    "                continue\n",
    "    return frequency      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDBt=preprocessing_bow(IMDB_train)\n",
    "yelpt=preprocessing_bow(yelp_train)\n",
    "IMDBv=preprocessing_bow(IMDB_valid)\n",
    "yelpv=preprocessing_bow(yelp_valid)\n",
    "IMDBtest=preprocessing_bow(IMDB_test)\n",
    "yelptest=preprocessing_bow(yelp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDBt_fbow=preprocessing_fbow(IMDB_train)\n",
    "yelpt_fbow=preprocessing_fbow(yelp_train)\n",
    "IMDBv_fbow=preprocessing_fbow(IMDB_valid)\n",
    "yelpv_fbow=preprocessing_fbow(yelp_valid)\n",
    "IMDBtest_fbow=preprocessing_fbow(IMDB_test)\n",
    "yelptest_fbow=preprocessing_fbow(yelp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMDBt_fbow=preprocessing_fbow(IMDB_train)\n",
    "#print(IMDBt_fbow[0])\n",
    "#print(sum(IMDBt_fbow[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# majority class, random class \n",
    "def majclass(x,y,test): \n",
    "    clf = DummyClassifier(strategy='most_frequent')\n",
    "    clf.fit(x,y)\n",
    "    return clf.predict(test)\n",
    "\n",
    "def randomclass(x,y,test):\n",
    "    clf = DummyClassifier(strategy='uniform')\n",
    "    clf.fit(x,y)\n",
    "    return clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive bayes\n",
    "def naivebayes(x,y,a,test):\n",
    "    clf = BernoulliNB(alpha = a)\n",
    "    clf.fit(x,y)\n",
    "    return clf.predict(test)\n",
    "\n",
    "def naivegaus(x,y,test):\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(x, y)\n",
    "    return clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### HYPERPARAMETER TUNING for NAIVE BAYES\n",
    "#parameters = np.linspace(0,20, num=20)\n",
    "parameters = [0, 0.0001, 0.001, 0.01, 0.1, 1, 2, 10, 12, 20, 50]\n",
    "#def findf1_score(IMDB_train,IMDBv,IMDB_valid,IMDBt,parameters): \n",
    "def testingnb(IMDB_valid, IMDBt, IMDB_train, parameters, IMDBv):\n",
    "    maxindex=0\n",
    "    maxf1=0\n",
    "    for i in range(len(parameters)): \n",
    "        x=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], parameters[i], IMDBv),average='micro')\n",
    "    #x1=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], i, IMDBv),average='micro')\n",
    "    #x2=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], i, IMDBv),average='macro')\n",
    "    #x3=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], i, IMDBv),average='samples')\n",
    "        print('parameter:', parameters[i])\n",
    "        print('x',x)\n",
    "        if (x>maxf1): \n",
    "            maxf1=x\n",
    "            maxindex=parameters[i]\n",
    "    return maxf1, maxindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear SVM\n",
    "def linear(x,y,a,test):\n",
    "    clf = LinearSVC(C=a, random_state=0, max_iter=100000)\n",
    "    clf.fit(x, y)\n",
    "    return clf.predict(test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear SVM for IMDB\n",
    "# linear SVM\n",
    "def linearIMDB(x,y,a,test):\n",
    "    clf = LinearSVC(C=a, random_state=0, dual=False, max_iter=100000)\n",
    "    clf.fit(x, y)\n",
    "    return clf.predict(test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### HYPERPARAMETER TUNING FOR LINEAR SVM\n",
    "#parameters = np.linspace(0,20, num=20)\n",
    "parameters = [0.0001, 0.001, 0.01, 0.1, 1, 2, 10, 20,100, 1000]\n",
    "#def findf1_score(IMDB_train,IMDBv,IMDB_valid,IMDBt,parameters): \n",
    "def testinglinearIMDB(IMDB_valid, IMDBt, IMDB_train, parameters, IMDBv):\n",
    "    maxindex=0\n",
    "    maxf1=0\n",
    "    for i in range(len(parameters)): \n",
    "        x=f1_score(IMDB_valid[1], linearIMDB(IMDBt, IMDB_train[1], parameters[i], IMDBv),average='micro')\n",
    "    #x1=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], i, IMDBv),average='micro')\n",
    "    #x2=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], i, IMDBv),average='macro')\n",
    "    #x3=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], i, IMDBv),average='samples')\n",
    "        print('linear parameter:', parameters[i])\n",
    "        print('x',x)\n",
    "        if (x>maxf1): \n",
    "            maxf1=x\n",
    "            maxindex=parameters[i]\n",
    "    return maxf1, maxindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### HYPERPARAMETER TUNING FOR LINEAR SVM\n",
    "#parameters = np.linspace(0,20, num=20)\n",
    "parameters = [0.0001, 0.001, 0.01, 0.1, 1, 2, 10, 20,100, 1000]\n",
    "#def findf1_score(IMDB_train,IMDBv,IMDB_valid,IMDBt,parameters): \n",
    "def testinglinear(IMDB_valid, IMDBt, IMDB_train, parameters, IMDBv):\n",
    "    maxindex=0\n",
    "    maxf1=0\n",
    "    for i in range(len(parameters)): \n",
    "        x=f1_score(IMDB_valid[1], linear(IMDBt, IMDB_train[1], parameters[i], IMDBv),average='micro')\n",
    "    #x1=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], i, IMDBv),average='micro')\n",
    "    #x2=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], i, IMDBv),average='macro')\n",
    "    #x3=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], i, IMDBv),average='samples')\n",
    "        print('linear parameter:', parameters[i])\n",
    "        print('x',x)\n",
    "        if (x>maxf1): \n",
    "            maxf1=x\n",
    "            maxindex=parameters[i]\n",
    "    return maxf1, maxindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree \n",
    "def decisiontree(x,y,test):\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(x, y)\n",
    "    return clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " # decision tree WITH MAX DEPTH\n",
    "def decisiontree_maxd(x,y,a,test):\n",
    "    clf = DecisionTreeClassifier(max_depth=a)\n",
    "    clf.fit(x, y)\n",
    "    return clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### testing max-depth\n",
    "maxdepths = np.linspace(1,32,32,endpoint=True)\n",
    "def testingdt(v, xt, x_train, maxdepths, xv):\n",
    "    maxindex=0\n",
    "    maxf1=0\n",
    "    for i in maxdepths: \n",
    "        x=f1_score(v[1], decisiontree_maxd(xt, x_train[1], i, xv), average='micro')\n",
    "        print('parameter:', i)\n",
    "        print('x',x)\n",
    "        if (x>maxf1): \n",
    "            maxf1=x\n",
    "            maxindex=i\n",
    "    return maxf1, maxindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree WITH MIN SAMPLES SPLIT\n",
    "def decisiontree1(x,y,b,test):\n",
    "    clf = DecisionTreeClassifier( min_samples_split=b,random_state=None)\n",
    "    clf.fit(x, y)\n",
    "    return clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### testing min_samples_split WITH MIN SAMPLES SPLIT\n",
    "min_samples_split = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "def testingdtmss(IMDB_valid, IMDBt, IMDB_train, min_samples_split, IMDBv):\n",
    "    maxindex=0\n",
    "    maxf1=0\n",
    "    for i in min_samples_split: \n",
    "        x=f1_score(IMDB_valid[1], decisiontree1(IMDBt, IMDB_train[1], i, IMDBv), average='weighted')\n",
    "        print('min_sample:', i)\n",
    "        print('x',x)\n",
    "        if (x>maxf1): \n",
    "            maxf1=x\n",
    "            maxindex=i\n",
    "    return maxf1, maxindex\n",
    "\n",
    "#a=maxp_dt\n",
    "#print(a)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# decision tree with maxdepth and min samples leaf \n",
    "def decisiontreex(x,y,a,c,test):\n",
    "    clf = DecisionTreeClassifier(max_depth=a,min_samples_leaf=c,random_state=None)\n",
    "    clf.fit(x, y)\n",
    "    return clf.predict(test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### testing min_sample_leaf\n",
    "min_samples_leaf = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "max_depth = np.linspace(1,32,32,endpoint=True)\n",
    "def testingdtx(IMDB_valid, IMDBt, IMDB_train, max_depth, min_samples_leaf, IMDBv):\n",
    "    maxindex=0\n",
    "    maxf1=0\n",
    "    for i in min_samples_leaf: \n",
    "        for y in max_depth: \n",
    "            x=f1_score(IMDB_valid[1], decisiontreex(IMDBt, IMDB_train[1],y, i, IMDBv), average='weighted')\n",
    "            print('min_sample:', i)\n",
    "            print('max_depth', y)\n",
    "            print('x',x)\n",
    "        if (x>maxf1): \n",
    "            maxf1=x\n",
    "            maxindex=y\n",
    "    return maxf1, maxindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree with min samples leaf \n",
    "def decisiontree2(x,y,c,test):\n",
    "    clf = DecisionTreeClassifier(min_samples_leaf=c,random_state=None)\n",
    "    clf.fit(x, y)\n",
    "    return clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### testing min_sample_leaf\n",
    "min_samples_leaf = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "def testingdtmsl(IMDB_valid, IMDBt, IMDB_train, min_samples_leaf, IMDBv):\n",
    "    maxindex=0\n",
    "    maxf1=0\n",
    "    for i in min_samples_leaf: \n",
    "        x=f1_score(IMDB_valid[1], decisiontree2(IMDBt, IMDB_train[1], i, IMDBv), average='weighted')\n",
    "        print('min_sample:', i)\n",
    "        print('x',x)\n",
    "        if (x>maxf1): \n",
    "            maxf1=x\n",
    "            maxindex=i\n",
    "    return maxf1, maxindex\n",
    "#a=maxp_dt\n",
    "#b=maxpmss_dt\n",
    "#print(a)\n",
    "#print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_measure for random classifier for yelp is: 0.19\n",
      "F1_measure for majority classifier for yelp is: 0.351\n"
     ]
    }
   ],
   "source": [
    "# F1_score for random and majority classifiers for yelp\n",
    "\n",
    "f1_yelp= f1_score(yelp_test[1], randomclass(yelpt, yelp_train[1], yelptest), average='micro')\n",
    "print(\"F1_measure for random classifier for yelp is:\", f1_yelp)\n",
    "\n",
    "f1_majority_yelp=f1_score(yelp_test[1], majclass(yelpt, yelp_train[1], yelptest), average='micro')\n",
    "print(\"F1_measure for majority classifier for yelp is:\", f1_majority_yelp)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question 2(b)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### PARAMETER TUNING FOR NB, using weighted, macro and micro\n",
    "parameters = [0, 0.0001, 0.001, 0.01, 0.1, 1, 2, 10, 12, 20, 50]\n",
    "#def findf1_score(IMDB_train,IMDBv,IMDB_valid,IMDBt,parameters): \n",
    "def testingnb1(IMDB_valid, IMDBt, IMDB_train, parameters, IMDBv):\n",
    "    maxindex=0\n",
    "    maxf1=0\n",
    "    for i in range(len(parameters)): \n",
    "        x=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], parameters[i], IMDBv),average='micro')\n",
    "    #x1=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], i, IMDBv),average='micro')\n",
    "    #x2=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], i, IMDBv),average='macro')\n",
    "    #x3=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], i, IMDBv),average='samples')\n",
    "        print('parameter:', parameters[i])\n",
    "        print('x',x)\n",
    "        \n",
    "\n",
    "testingnb1(yelp_valid, yelpt, yelp_train, parameters, yelpv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "parameters = [0, 0.0001, 0.001, 0.01, 0.1, 1, 2, 10, 12, 20, 50]\n",
    "#def findf1_score(IMDB_train,IMDBv,IMDB_valid,IMDBt,parameters): \n",
    "def testingnb2(IMDB_valid, IMDBt, IMDB_train, parameters, IMDBv):\n",
    "    maxindex=0\n",
    "    maxf1=0\n",
    "    for i in range(len(parameters)): \n",
    "        x=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], parameters[i], IMDBv),average='micro')\n",
    "    #x1=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], i, IMDBv),average='micro')\n",
    "    #x2=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], i, IMDBv),average='macro')\n",
    "    #x3=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], i, IMDBv),average='samples')\n",
    "        print('parameter:', parameters[i])\n",
    "        print('x',x)\n",
    "        \n",
    "parameters = [0, 0.0001, 0.001, 0.01, 0.1, 1, 2, 10, 12, 20, 50]\n",
    "testingnb2(yelp_valid, yelpt, yelp_train, parameters, yelpv)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Testing max depth and linear space leaf \n",
    "\n",
    "maxf1_dt_bow, maxp_dt_bow = testingdtx(yelp_valid, yelpt, yelp_train, max_depth, min_samples_leaf,  yelpv)\n",
    "#maxf1_yelporg = f1_score(yelp_valid[1],decisiontree(yelpt, yelp_train[1], yelpv), average='micro')\n",
    "#print(\"Original F1 score for decision tree without parameter tuning:\", maxf1_yelporg)\n",
    "print(\"Max F1 for DecisionTree with decision tree, maxdepth and linsampleleeaf:\",maxf1_dt_bow)\n",
    "print(\"seen at parameter:\", maxp_dt_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter: 0\n",
      "x 0.38\n",
      "parameter: 0.0001\n",
      "x 0.404\n",
      "parameter: 0.001\n",
      "x 0.42299999999999993\n",
      "parameter: 0.01\n",
      "x 0.426\n",
      "parameter: 0.1\n",
      "x 0.411\n",
      "parameter: 1\n",
      "x 0.384\n",
      "parameter: 2\n",
      "x 0.38499999999999995\n",
      "parameter: 10\n",
      "x 0.377\n",
      "parameter: 12\n",
      "x 0.378\n",
      "parameter: 20\n",
      "x 0.377\n",
      "parameter: 50\n",
      "x 0.38499999999999995\n",
      "Max F1 for Naive Bayes: 0.426\n",
      "seen at parameter: 0.01\n",
      "parameter: 1.0\n",
      "x 0.38499999999999995\n",
      "parameter: 2.0\n",
      "x 0.376\n",
      "parameter: 3.0\n",
      "x 0.376\n",
      "parameter: 4.0\n",
      "x 0.376\n",
      "parameter: 5.0\n",
      "x 0.378\n",
      "parameter: 6.0\n",
      "x 0.388\n",
      "parameter: 7.0\n",
      "x 0.393\n",
      "parameter: 8.0\n",
      "x 0.404\n",
      "parameter: 9.0\n",
      "x 0.391\n",
      "parameter: 10.0\n",
      "x 0.39\n",
      "parameter: 11.0\n",
      "x 0.372\n",
      "parameter: 12.0\n",
      "x 0.374\n",
      "parameter: 13.0\n",
      "x 0.374\n",
      "parameter: 14.0\n",
      "x 0.35800000000000004\n",
      "parameter: 15.0\n",
      "x 0.361\n",
      "parameter: 16.0\n",
      "x 0.352\n",
      "parameter: 17.0\n",
      "x 0.363\n",
      "parameter: 18.0\n",
      "x 0.375\n",
      "parameter: 19.0\n",
      "x 0.363\n",
      "parameter: 20.0\n",
      "x 0.36\n",
      "parameter: 21.0\n",
      "x 0.362\n",
      "parameter: 22.0\n",
      "x 0.36\n",
      "parameter: 23.0\n",
      "x 0.368\n",
      "parameter: 24.0\n",
      "x 0.35500000000000004\n",
      "parameter: 25.0\n",
      "x 0.353\n",
      "parameter: 26.0\n",
      "x 0.36499999999999994\n",
      "parameter: 27.0\n",
      "x 0.348\n",
      "parameter: 28.0\n",
      "x 0.333\n",
      "parameter: 29.0\n",
      "x 0.353\n",
      "parameter: 30.0\n",
      "x 0.35500000000000004\n",
      "parameter: 31.0\n",
      "x 0.341\n",
      "parameter: 32.0\n",
      "x 0.354\n",
      "Original F1 score for decision tree without parameter tuning: 0.332\n",
      "Max F1 for DecisionTree: 0.404\n",
      "seen at parameter: 8.0\n",
      "linear parameter: 0.0001\n",
      "x 0.433\n",
      "linear parameter: 0.001\n",
      "x 0.493\n",
      "linear parameter: 0.01\n",
      "x 0.499\n",
      "linear parameter: 0.1\n",
      "x 0.473\n",
      "linear parameter: 1\n",
      "x 0.435\n",
      "linear parameter: 2\n",
      "x 0.439\n",
      "linear parameter: 10\n",
      "x 0.434\n",
      "linear parameter: 20\n",
      "x 0.436\n",
      "linear parameter: 1000\n",
      "x 0.426\n",
      "Max F1 for Linear: 0.499\n",
      "seen at parameter: 0.01\n"
     ]
    }
   ],
   "source": [
    "##### PARAMETER TUNING FOR YELP_BBOW, NAIVE BAYES, DECISION TREES, LINEAR SVM\n",
    "parameters = [0, 0.0001, 0.001, 0.01, 0.1, 1, 2, 10, 12, 20, 50]\n",
    "maxf1_nb_bow, maxp_nb_bow = testingnb(yelp_valid, yelpt, yelp_train, parameters, yelpv)\n",
    "print(\"Max F1 for Naive Bayes:\",maxf1_nb_bow)\n",
    "print(\"seen at parameter:\", maxp_nb_bow)\n",
    "\n",
    "maxdepths = np.linspace(1,32,32,endpoint=True)\n",
    "maxf1_dt_bow, maxp_dt_bow = testingdt(yelp_valid, yelpt, yelp_train, maxdepths, yelpv)\n",
    "maxf1_yelporg = f1_score(yelp_valid[1],decisiontree(yelpt, yelp_train[1], yelpv), average='micro')\n",
    "print(\"Original F1 score for decision tree without parameter tuning:\", maxf1_yelporg)\n",
    "print(\"Max F1 for DecisionTree:\",maxf1_dt_bow)\n",
    "print(\"seen at parameter:\", maxp_dt_bow)\n",
    "\n",
    "parameters_lin = [0.0001, 0.001, 0.01, 0.1, 1, 2, 10, 20,100, 1000]\n",
    "maxf1_linear_bow, maxp_linear_bow = testinglinear(yelp_valid, yelpt, yelp_train, parameters_lin, yelpv)\n",
    "print(\"Max F1 for Linear:\",maxf1_linear_bow)\n",
    "print(\"seen at parameter:\", maxp_linear_bow)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### For decision tree, test dt_min_leaves & dt_min_split \n",
    "min_samples_split = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "maxf1mss_dt_yelp, maxpmss_dt_yelp = testingdtmss(yelp_valid, yelpt, yelp_train, min_samples_split, yelpv)\n",
    "print(\"Max F1 for Decision Tree:\",maxf1mss_dt_yelp)\n",
    "print(\"seen at parameter:\", maxpmss_dt_yelp)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "min_samples_leaf = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "maxf1msl_dt_yelp, maxpmsl_dt = testingdtmsl(yelp_valid, yelpt, yelp_train,min_samples_leaf, yelpv)\n",
    "print(\"Max F1 for Decision Tree:\",maxf1msl_dt_yelp)\n",
    "print(\"seen at parameter:\", maxpmsl_dt_yelp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nb_f1_train = f1_score(yelp_train[1], naivebayes(yelpt, yelp_train[1], maxp_nb_bow, yelpt),average='micro')\n",
    "gb_f1_train = f1_score(yelp_train[1], naivegaus(yelpt, yelp_train[1], yelpt), average=\"micro\")\n",
    "\n",
    "\n",
    "nb_f1_valid = f1_score(yelp_valid[1], naivebayes(yelpt, yelp_train[1], maxp_nb_bow, yelpv),average='micro')\n",
    "gb_f1_valid = f1_score(yelp_valid[1], naivegaus(yelpt, yelp_train[1], yelpv), average=\"micro\")\n",
    "\n",
    "nb_f1_test = f1_score(yelp_test[1], naivebayes(yelpt, yelp_train[1], maxp_nb_bow, yelptest),average='micro')\n",
    "gb_f1_test = f1_score(yelp_test[1], naivegaus(yelpt, yelp_train[1], yelptest), average=\"micro\")\n",
    "\n",
    "print(\"F1 FOR YELP BBOW\")\n",
    "print(\"Max F1 for Naive Bayes for training:\", nb_f1_train)\n",
    "print(\"seen at parameter:\", maxp_nb_bow)\n",
    "#print(\"Max F1 for Gaussian Bayes for training:\", gb_f1_train)\n",
    "\n",
    "print(\"Max F1 for Naive Bayes for validation:\", nb_f1_valid)\n",
    "print(\"seen at parameter:\", maxp_nb_bow)\n",
    "#print(\"Max F1 for Gaussian Bayes for validation:\", gb_f1_valid)\n",
    "\n",
    "print(\"Max F1 for Naive Bayes for testing:\", nb_f1_test)\n",
    "print(\"seen at parameter:\", maxp_nb_bow)\n",
    "#print(\"Max F1 for Gaussian Bayes for testing:\", gb_f1_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question 2(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 FOR YELP BBOW\n",
      "Max F1 for Naive Bayes for training: 0.7458571428571429\n",
      "seen at parameter: 0.01\n",
      "Max F1 for Naive Bayes for validation: 0.426\n",
      "seen at parameter: 0.01\n",
      "Max F1 for Naive Bayes for testing: 0.443\n",
      "seen at parameter: 0.01\n",
      "Max F1 for Decision Tree for training: 0.48014285714285715\n",
      "seen at parameter: 8.0\n",
      "Max F1 for Decision Tree for validation: 0.403\n",
      "seen at parameter: 8.0\n",
      "Max F1 for Decision Tree for testing: 0.3995\n",
      "seen at parameter: 8.0\n",
      "Max F1 for SVM for training: 0.8418571428571429\n",
      "seen at parameter: 0.01\n",
      "Max F1 for SVM for validation: 0.499\n",
      "seen at parameter: 0.01\n",
      "Max F1 for SVM for testing: 0.5075\n",
      "seen at parameter: 0.01\n"
     ]
    }
   ],
   "source": [
    "####### Training, validation and test F1-measure for BBOW\n",
    "nb_f1_train = f1_score(yelp_train[1], naivebayes(yelpt, yelp_train[1], maxp_nb_bow, yelpt),average='micro')\n",
    "gb_f1_train = f1_score(yelp_train[1], naivegaus(yelpt, yelp_train[1], yelpt), average=\"micro\")\n",
    "\n",
    "\n",
    "nb_f1_valid = f1_score(yelp_valid[1], naivebayes(yelpt, yelp_train[1], maxp_nb_bow, yelpv),average='micro')\n",
    "gb_f1_valid = f1_score(yelp_valid[1], naivegaus(yelpt, yelp_train[1], yelpv), average=\"micro\")\n",
    "\n",
    "nb_f1_test = f1_score(yelp_test[1], naivebayes(yelpt, yelp_train[1], maxp_nb_bow, yelptest),average='micro')\n",
    "gb_f1_test = f1_score(yelp_test[1], naivegaus(yelpt, yelp_train[1], yelptest), average=\"micro\")\n",
    "\n",
    "\n",
    "dt_f1_train=f1_score(yelp_train[1], decisiontree_maxd(yelpt, yelp_train[1], maxp_dt_bow, yelpt), average='micro')\n",
    "dt_f1_valid=f1_score(yelp_valid[1], decisiontree_maxd(yelpt, yelp_train[1], maxp_dt_bow, yelpv), average='micro')\n",
    "dt_f1_test=f1_score(yelp_test[1], decisiontree_maxd(yelpt, yelp_train[1], maxp_dt_bow, yelptest), average='micro')\n",
    "\n",
    "svm_f1_train=f1_score(yelp_train[1], linear(yelpt, yelp_train[1], maxp_linear_bow, yelpt),average='micro')\n",
    "svm_f1_valid=f1_score(yelp_valid[1], linear(yelpt, yelp_train[1], maxp_linear_bow, yelpv),average='micro')\n",
    "svm_f1_test=f1_score(yelp_test[1], linear(yelpt, yelp_train[1], maxp_linear_bow, yelptest),average='micro')\n",
    "\n",
    "print(\"F1 FOR YELP BBOW\")\n",
    "print(\"Max F1 for Naive Bayes for training:\", nb_f1_train)\n",
    "print(\"seen at parameter:\", maxp_nb_bow)\n",
    "#print(\"Max F1 for Gaussian Bayes for training:\", gb_f1_train)\n",
    "\n",
    "print(\"Max F1 for Naive Bayes for validation:\", nb_f1_valid)\n",
    "print(\"seen at parameter:\", maxp_nb_bow)\n",
    "#print(\"Max F1 for Gaussian Bayes for validation:\", gb_f1_valid)\n",
    "\n",
    "print(\"Max F1 for Naive Bayes for testing:\", nb_f1_test)\n",
    "print(\"seen at parameter:\", maxp_nb_bow)\n",
    "#print(\"Max F1 for Gaussian Bayes for testing:\", gb_f1_test)\n",
    "\n",
    "print(\"Max F1 for Decision Tree for training:\", dt_f1_train)\n",
    "print(\"seen at parameter:\",maxp_dt_bow)\n",
    "print(\"Max F1 for Decision Tree for validation:\", dt_f1_valid)\n",
    "print(\"seen at parameter:\",maxp_dt_bow)\n",
    "print(\"Max F1 for Decision Tree for testing:\", dt_f1_test)\n",
    "print(\"seen at parameter:\",maxp_dt_bow)\n",
    "\n",
    "print(\"Max F1 for SVM for training:\", svm_f1_train)\n",
    "print(\"seen at parameter:\",maxp_linear_bow)\n",
    "print(\"Max F1 for SVM for validation:\", svm_f1_valid)\n",
    "print(\"seen at parameter:\",maxp_linear_bow)\n",
    "print(\"Max F1 for SVM for testing:\", svm_f1_test)\n",
    "print(\"seen at parameter:\",maxp_linear_bow)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question 3(b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter: 0\n",
      "x 0.38\n",
      "parameter: 0.0001\n",
      "x 0.404\n",
      "parameter: 0.001\n",
      "x 0.42299999999999993\n",
      "parameter: 0.01\n",
      "x 0.426\n",
      "parameter: 0.1\n",
      "x 0.411\n",
      "parameter: 1\n",
      "x 0.384\n",
      "parameter: 2\n",
      "x 0.38499999999999995\n",
      "parameter: 10\n",
      "x 0.377\n",
      "parameter: 12\n",
      "x 0.378\n",
      "parameter: 20\n",
      "x 0.377\n",
      "parameter: 50\n",
      "x 0.38499999999999995\n",
      "Max F1 for Naive Bayes: 0.426\n",
      "seen at parameter: 0.01\n",
      "parameter: 1.0\n",
      "x 0.383\n",
      "parameter: 2.0\n",
      "x 0.384\n",
      "parameter: 3.0\n",
      "x 0.383\n",
      "parameter: 4.0\n",
      "x 0.388\n",
      "parameter: 5.0\n",
      "x 0.39200000000000007\n",
      "parameter: 6.0\n",
      "x 0.40700000000000003\n",
      "parameter: 7.0\n",
      "x 0.41\n",
      "parameter: 8.0\n",
      "x 0.425\n",
      "parameter: 9.0\n",
      "x 0.425\n",
      "parameter: 10.0\n",
      "x 0.42999999999999994\n",
      "parameter: 11.0\n",
      "x 0.40599999999999997\n",
      "parameter: 12.0\n",
      "x 0.40599999999999997\n",
      "parameter: 13.0\n",
      "x 0.395\n",
      "parameter: 14.0\n",
      "x 0.368\n",
      "parameter: 15.0\n",
      "x 0.353\n",
      "parameter: 16.0\n",
      "x 0.35500000000000004\n",
      "parameter: 17.0\n",
      "x 0.372\n",
      "parameter: 18.0\n",
      "x 0.364\n",
      "parameter: 19.0\n",
      "x 0.349\n",
      "parameter: 20.0\n",
      "x 0.347\n",
      "parameter: 21.0\n",
      "x 0.339\n",
      "parameter: 22.0\n",
      "x 0.362\n",
      "parameter: 23.0\n",
      "x 0.359\n",
      "parameter: 24.0\n",
      "x 0.354\n",
      "parameter: 25.0\n",
      "x 0.347\n",
      "parameter: 26.0\n",
      "x 0.341\n",
      "parameter: 27.0\n",
      "x 0.334\n",
      "parameter: 28.0\n",
      "x 0.332\n",
      "parameter: 29.0\n",
      "x 0.342\n",
      "parameter: 30.0\n",
      "x 0.335\n",
      "parameter: 31.0\n",
      "x 0.338\n",
      "parameter: 32.0\n",
      "x 0.335\n",
      "Max F1 for DecisionTree: 0.42999999999999994\n",
      "seen at parameter: 10.0\n",
      "linear parameter: 0.0001\n",
      "x 0.356\n",
      "linear parameter: 0.001\n",
      "x 0.356\n",
      "linear parameter: 0.01\n",
      "x 0.378\n",
      "linear parameter: 0.1\n",
      "x 0.409\n",
      "linear parameter: 1\n",
      "x 0.444\n",
      "linear parameter: 2\n",
      "x 0.461\n",
      "linear parameter: 10\n",
      "x 0.501\n",
      "linear parameter: 20\n",
      "x 0.501\n",
      "linear parameter: 100\n",
      "x 0.494\n",
      "linear parameter: 1000\n",
      "x 0.465\n",
      "Max F1 for Linear: 0.501\n",
      "seen at parameter: 10\n"
     ]
    }
   ],
   "source": [
    "##### PARAMETER TUNING FOR YELP_FBOW, NAIVE BAYES, DECISION TREES, LINEAR SVM\n",
    "parameters = [0, 0.0001, 0.001, 0.01, 0.1, 1, 2, 10, 12, 20, 50]\n",
    "maxf1_nb_fbow, maxp_nb_fbow = testingnb(yelp_valid, yelpt_fbow, yelp_train, parameters, yelpv_fbow)\n",
    "print(\"Max F1 for Naive Bayes:\",maxf1_nb_fbow)\n",
    "print(\"seen at parameter:\", maxp_nb_fbow)\n",
    "\n",
    "maxf1_dt_fbow, maxp_dt_fbow = testingdt(yelp_valid, yelpt_fbow, yelp_train, maxdepths, yelpv_fbow)\n",
    "print(\"Max F1 for DecisionTree:\",maxf1_dt_fbow)\n",
    "print(\"seen at parameter:\", maxp_dt_fbow)\n",
    "\n",
    "parameters_lin = [0.0001, 0.001, 0.01, 0.1, 1, 2, 10, 20, 100, 1000]\n",
    "maxf1_linear_fbow, maxp_linear_fbow = testinglinear(yelp_valid, yelpt_fbow, yelp_train, parameters_lin, yelpv_fbow)\n",
    "print(\"Max F1 for Linear:\",maxf1_linear_fbow)\n",
    "print(\"seen at parameter:\", maxp_linear_fbow)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "min_samples_leaf = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "maxf1msl_dt_yelp, maxpmsl_dt = testingdtmsl(yelp_valid, yelpt, yelp_train,min_samples_leaf, yelpv)\n",
    "print(\"Max F1 for Decision Tree:\",maxf1msl_dt_yelp)\n",
    "print(\"seen at parameter:\", maxpmsl_dt_yelp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 3(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max F1 for Gaussian Bayes for training: 0.8045714285714286\n",
      "Max F1 for Gaussian Bayes for validation: 0.295\n",
      "Max F1 for Gaussian Bayes for testing: 0.31\n",
      "Max F1 for Decision Tree for training: 0.5428571428571428\n",
      "seen at parameter: 10.0\n",
      "Max F1 for Decision Tree for validation: 0.424\n",
      "seen at parameter: 10.0\n",
      "Max F1 for Decision Tree for testing: 0.401\n",
      "seen at parameter: 10.0\n",
      "Max F1 for SVM for training: 0.6414285714285715\n",
      "seen at parameter: 10\n",
      "Max F1 for SVM for validation: 0.501\n",
      "seen at parameter: 10\n",
      "Max F1 for SVM for testing: 0.508\n",
      "seen at parameter: 10\n"
     ]
    }
   ],
   "source": [
    "###### F1 FOR YELP FBOW\n",
    "####### Training, validation and test F1-measure \n",
    "# Naive bayes F1 using best parameter = 0.1\n",
    "parameter=maxp_nb_fbow\n",
    "\n",
    "nb_f1_train_fbow = f1_score(yelp_train[1], naivebayes(yelpt_fbow, yelp_train[1], maxp_nb_fbow, yelpt_fbow),average='micro')\n",
    "gb_f1_train_fbow = f1_score(yelp_train[1], naivegaus(yelpt_fbow, yelp_train[1], yelpt_fbow), average=\"micro\")\n",
    "\n",
    "\n",
    "nb_f1_valid_fbow = f1_score(yelp_valid[1], naivebayes(yelpt_fbow, yelp_train[1], maxp_nb_fbow, yelpv_fbow),average='micro')\n",
    "gb_f1_valid_fbow = f1_score(yelp_valid[1], naivegaus(yelpt_fbow, yelp_train[1], yelpv_fbow), average=\"micro\")\n",
    "\n",
    "nb_f1_test_fbow = f1_score(yelp_test[1], naivebayes(yelpt_fbow, yelp_train[1], maxp_nb_fbow, yelptest_fbow),average='micro')\n",
    "gb_f1_test_fbow = f1_score(yelp_test[1], naivegaus(yelpt_fbow, yelp_train[1], yelptest_fbow), average=\"micro\")\n",
    "\n",
    "\n",
    "dt_f1_train_fbow=f1_score(yelp_train[1], decisiontree_maxd(yelpt_fbow, yelp_train[1], maxp_dt_fbow, yelpt_fbow), average='micro')\n",
    "dt_f1_valid_fbow=f1_score(yelp_valid[1], decisiontree_maxd(yelpt_fbow, yelp_train[1], maxp_dt_fbow, yelpv_fbow), average='micro')\n",
    "dt_f1_test_fbow=f1_score(yelp_test[1], decisiontree_maxd(yelpt_fbow, yelp_train[1], maxp_dt_fbow, yelptest_fbow), average='micro')\n",
    "\n",
    "svm_f1_train_fbow=f1_score(yelp_train[1], linear(yelpt_fbow, yelp_train[1], maxp_linear_fbow, yelpt_fbow),average='micro')\n",
    "svm_f1_valid_fbow=f1_score(yelp_valid[1], linear(yelpt_fbow, yelp_train[1], maxp_linear_fbow, yelpv_fbow),average='micro')\n",
    "svm_f1_test_fbow=f1_score(yelp_test[1], linear(yelpt_fbow, yelp_train[1], maxp_linear_fbow, yelptest_fbow),average='micro')\n",
    "\n",
    "#print(\"Max F1 for Naive Bayes for training:\", nb_f1_train_fbow)\n",
    "#print(\"seen at parameter:\", maxp_nb_fbow)\n",
    "print(\"Max F1 for Gaussian Bayes for training:\", gb_f1_train_fbow)\n",
    "#print(\"Max F1 for Naive Bayes for validation:\", nb_f1_valid_fbow)\n",
    "#print(\"seen at parameter:\", maxp_nb_fbow)\n",
    "print(\"Max F1 for Gaussian Bayes for validation:\", gb_f1_valid_fbow)\n",
    "#print(\"Max F1 for Naive Bayes for testing:\", nb_f1_test_fbow)\n",
    "#print(\"seen at parameter:\", maxp_nb_fbow)\n",
    "print(\"Max F1 for Gaussian Bayes for testing:\", gb_f1_test_fbow)\n",
    "\n",
    "print(\"Max F1 for Decision Tree for training:\", dt_f1_train_fbow)\n",
    "print(\"seen at parameter:\",maxp_dt_fbow)\n",
    "print(\"Max F1 for Decision Tree for validation:\", dt_f1_valid_fbow)\n",
    "print(\"seen at parameter:\",maxp_dt_fbow)\n",
    "print(\"Max F1 for Decision Tree for testing:\", dt_f1_test_fbow)\n",
    "print(\"seen at parameter:\",maxp_dt_fbow)\n",
    "\n",
    "print(\"Max F1 for SVM for training:\", svm_f1_train_fbow)\n",
    "print(\"seen at parameter:\",maxp_linear_fbow)\n",
    "print(\"Max F1 for SVM for validation:\", svm_f1_valid_fbow)\n",
    "print(\"seen at parameter:\",maxp_linear_fbow)\n",
    "print(\"Max F1 for SVM for testing:\", svm_f1_test_fbow)\n",
    "print(\"seen at parameter:\",maxp_linear_fbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_measure for random classifier for IMDB is: 0.49648\n"
     ]
    }
   ],
   "source": [
    "# F1 score for IMDB using random classifier \n",
    "\n",
    "f1_IMDB= f1_score(IMDB_test[1], randomclass(IMDBt, IMDB_train[1], IMDBtest), average='micro')\n",
    "print(\"F1_measure for random classifier for IMDB is:\", f1_IMDB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 4(b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear parameter: 0.0001\n",
      "x 0.8317\n",
      "linear parameter: 0.001\n",
      "x 0.8675\n",
      "linear parameter: 0.01\n",
      "x 0.8746\n",
      "linear parameter: 0.1\n",
      "x 0.8568\n",
      "linear parameter: 1\n",
      "x 0.8444\n",
      "linear parameter: 2\n",
      "x 0.8424000000000001\n",
      "linear parameter: 10\n",
      "x 0.8406\n",
      "linear parameter: 20\n",
      "x 0.8408\n",
      "linear parameter: 100\n",
      "x 0.8396999999999999\n",
      "linear parameter: 1000\n",
      "x 0.8408\n",
      "Max F1 for Linear: 0.8746\n",
      "seen at parameter: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Parameter testing for linear SVM IMDB\n",
    "\n",
    "parameters = [0.0001, 0.001, 0.01, 0.1, 1, 2, 10, 20,100, 1000]\n",
    "maxf1_linear1, maxp_linear1 = testinglinearIMDB(IMDB_valid, IMDBt, IMDB_train, parameters, IMDBv)\n",
    "print(\"Max F1 for Linear:\",maxf1_linear1)\n",
    "print(\"seen at parameter:\", maxp_linear1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter: 0.0001\n",
      "x 0.8424000000000001\n",
      "parameter: 0.001\n",
      "x 0.8427\n",
      "parameter: 0.01\n",
      "x 0.8431000000000001\n",
      "parameter: 0.1\n",
      "x 0.8436\n",
      "parameter: 1\n",
      "x 0.8424000000000001\n",
      "parameter: 2\n",
      "x 0.8416999999999999\n",
      "parameter: 10\n",
      "x 0.8378\n",
      "parameter: 20\n",
      "x 0.8359\n",
      "parameter: 100\n",
      "x 0.8115\n",
      "parameter: 1000\n",
      "x 0.7209\n",
      "Max F1 for Naive Bayes: 0.8436\n",
      "seen at parameter: 0.1\n"
     ]
    }
   ],
   "source": [
    "# testing validation f1_score for Naive Bayes IMDB \n",
    "\n",
    "parameters = [0.0001, 0.001, 0.01, 0.1, 1, 2, 10, 20,100, 1000]\n",
    "maxf1_nb1, maxp_nb1 = testingnb(IMDB_valid, IMDBt, IMDB_train, parameters, IMDBv)\n",
    "print(\"Max F1 for Naive Bayes:\",maxf1_nb1)\n",
    "print(\"seen at parameter:\", maxp_nb1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original decision tree (no parameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6978\n"
     ]
    }
   ],
   "source": [
    "# F1 Score for original decision tree with no hyperparameter tuning \n",
    "\n",
    "maxf1_original = f1_score(IMDB_valid[1],decisiontree(IMDBt, IMDB_train[1], IMDBv), average='micro')\n",
    "print(maxf1_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree (tuning max depth from 1-32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter: 1.0\n",
      "x 0.6113\n",
      "parameter: 2.0\n",
      "x 0.6453\n",
      "parameter: 3.0\n",
      "x 0.6664\n",
      "parameter: 4.0\n",
      "x 0.6689\n",
      "parameter: 5.0\n",
      "x 0.6815\n",
      "parameter: 6.0\n",
      "x 0.6957\n",
      "parameter: 7.0\n",
      "x 0.7053\n",
      "parameter: 8.0\n",
      "x 0.7045\n",
      "parameter: 9.0\n",
      "x 0.7046\n",
      "parameter: 10.0\n",
      "x 0.7106999999999999\n",
      "parameter: 11.0\n",
      "x 0.712\n",
      "parameter: 12.0\n",
      "x 0.7205999999999999\n",
      "parameter: 13.0\n",
      "x 0.7207\n",
      "parameter: 14.0\n",
      "x 0.7242\n",
      "parameter: 15.0\n",
      "x 0.7239\n",
      "parameter: 16.0\n",
      "x 0.7217000000000001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-099c14c29f89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# testing validation f1_score for decision tree with max depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmaxdepths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmaxf1_dt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxp_dt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestingdt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMDB_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMDBt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMDB_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxdepths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMDBv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Max F1 for DecisionTree:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxf1_dt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"seen at parameter:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxp_dt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-b24567b273c0>\u001b[0m in \u001b[0;36mtestingdt\u001b[0;34m(v, xt, x_train, maxdepths, xv)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmaxf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmaxdepths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecisiontree_maxd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'parameter:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-7d427f9f6f30>\u001b[0m in \u001b[0;36mdecisiontree_maxd\u001b[0;34m(x, y, a, test)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecisiontree_maxd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m    \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m    \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    363\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# testing validation f1_score for decision tree with max depth \n",
    "maxdepths = np.linspace(1,32,32,endpoint=True)\n",
    "maxf1_dt1, maxp_dt1 = testingdt(IMDB_valid, IMDBt, IMDB_train, maxdepths, IMDBv)\n",
    "print(\"Max F1 for DecisionTree:\",maxf1_dt1)\n",
    "print(\"seen at parameter:\", maxp_dt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree (Min Sample Split tuning from 0.1-1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_sample: 0.1\n",
      "x 0.721465416415963\n",
      "min_sample: 0.2\n",
      "x 0.6980133308372874\n",
      "min_sample: 0.30000000000000004\n",
      "x 0.6980133308372874\n",
      "min_sample: 0.4\n",
      "x 0.6980133308372874\n",
      "min_sample: 0.5\n",
      "x 0.6691405945531125\n",
      "min_sample: 0.6\n",
      "x 0.653336891326543\n",
      "min_sample: 0.7000000000000001\n",
      "x 0.653336891326543\n",
      "min_sample: 0.8\n",
      "x 0.580417154295444\n",
      "min_sample: 0.9\n",
      "x 0.580417154295444\n",
      "min_sample: 1.0\n",
      "x 0.580417154295444\n",
      "Max F1 for Decision Tree: 0.721465416415963\n",
      "seen at parameter: 0.1\n"
     ]
    }
   ],
   "source": [
    "# testing validation f1_score for decision tree with min sample split\n",
    "min_samples_split = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "maxf1mss_dt, maxpmss_dt = testingdtmss(IMDB_valid, IMDBt, IMDB_train, min_samples_split, IMDBv)\n",
    "print(\"Max F1 for Decision Tree:\",maxf1mss_dt)\n",
    "print(\"seen at parameter:\", maxpmss_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree (Min Sample Leaf tuning from 0.1 - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_sample: 0.1\n",
      "x 0.6492301383028154\n",
      "min_sample: 0.2\n",
      "x 0.6303876794396931\n",
      "min_sample: 0.30000000000000004\n",
      "x 0.558060448739638\n",
      "min_sample: 0.4\n",
      "x 0.5524427902976884\n",
      "min_sample: 0.5\n",
      "x 0.3333333333333333\n",
      "Max F1 for Decision Tree: 0.6492301383028154\n",
      "seen at parameter: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Parameter tuning for decision tree with min sample leaf\n",
    "min_samples_leaf = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "maxf1msl_dt, maxpmsl_dt = testingdtmsl(IMDB_valid, IMDBt, IMDB_train,min_samples_leaf, IMDBv)\n",
    "print(\"Max F1 for Decision Tree:\",maxf1msl_dt)\n",
    "print(\"seen at parameter:\", maxpmsl_dt)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in enumerate(parameters): \n",
    "    x=f1_score(IMDB_valid[1], naivegaus(IMDBt, IMDB_train[1], i, IMDBv),average='weighted')\n",
    "    #x1=f1_score(IMDB_valid[1], naivegaus(IMDBt, IMDB_train[1], i, IMDBv),average='micro')\n",
    "    #x2=f1_score(IMDB_valid[1], naivegaus(IMDBt, IMDB_train[1], i, IMDBv),average='macro')\n",
    "    #x3=f1_score(IMDB_valid[1], naivegaus(IMDBt, IMDB_train[1], i, IMDBv),average='samples')\n",
    "    print('ng1',x)\n",
    "    #print('ng2',x1)\n",
    "    #print('ng3', x2)\n",
    "    #print('ng4',x3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# MICRO\n",
    "parameters = [0, 0.0001, 0.001, 0.01, 0.1, 1, 2, 10, 12, 20, 50]\n",
    "#def testingnbmicro(IMDB_valid, IMDBt, IMDB_train, parameters, IMDBv):\n",
    "#    maxindex=0\n",
    "#    maxf1=0   \n",
    "#    for i in range(len(parameters)): \n",
    "#        \n",
    "#        x1=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], parameters[i], IMDBv),average='micro')\n",
    "#        print(\"parameters\",parameters[i])\n",
    "#        print('x1',x1)\n",
    "#        if (x1>maxf1): \n",
    "#            maxf1=x1\n",
    "#            maxindex=parameters[i]\n",
    "#    return maxf1, maxindex"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "maxf1micro_nb, maxpmicro_nb = testingnbmicro(IMDB_valid, IMDBt, IMDB_train, parameters, IMDBv)\n",
    "print(\"Max F1 for Naive Bayes:\",maxf1micro_nb)\n",
    "print(\"seen at parameter:\", maxpmicro_nb)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# MACRO\n",
    "parameters = [0, 0.0001, 0.001, 0.01, 0.1, 1, 2, 10, 12, 20, 50]\n",
    "def testingnbmacro(IMDB_valid, IMDBt, IMDB_train, parameters, IMDBv):\n",
    "    maxindex=0\n",
    "    maxf1=0 \n",
    "    for i in range(len(parameters)): \n",
    "        \n",
    "        x2=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], parameters[i], IMDBv),average='macro')\n",
    "    \n",
    "        print(\"parameters\",parameters[i])\n",
    "        print('x2', x2)\n",
    "        if (x2>maxf1): \n",
    "            maxf1=x2\n",
    "            maxindex=parameters[i]\n",
    "    return maxf1, maxindex"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "maxf1macro_nb, maxpmacro_nb = testingnbmicro(IMDB_valid, IMDBt, IMDB_train, parameters, IMDBv)\n",
    "print(\"Max F1 for Naive Bayes:\",maxf1macro_nb)\n",
    "print(\"seen at parameter:\", maxpmacro_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAMPLES \n",
    "for i in range(len(parameters)): \n",
    "    #x=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], i, IMDBv),average='weighted')\n",
    "    #x1=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], i, IMDBv),average='micro')\n",
    "    #x2=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], i, IMDBv),average='macro')\n",
    "    x3=f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], parameters[i], IMDBv),average='samples')\n",
    "    #print('x',x)\n",
    "    #print('x1',x1)\n",
    "    #print('x2', x2)\n",
    "    print(\"parameters\",parameters[i])\n",
    "    print('x3',x3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "svm_f1_train=f1_score(IMDB_train[1], linearIMDB(IMDBt, IMDB_train[1], maxp_linear1, IMDBt),average='micro')\n",
    "svm_f1_valid=f1_score(IMDB_valid[1], linearIMDB(IMDBt, IMDB_train[1], maxp_linear1, IMDBv),average='micro')\n",
    "svm_f1_test=f1_score(IMDB_test[1], linearIMDB(IMDBt, IMDB_train[1], maxp_linear1, IMDBtest),average='micro')\n",
    "\n",
    "print(\"Max F1 for SVM for training:\", svm_f1_train)\n",
    "print(\"seen at parameter:\",maxp_linear1)\n",
    "print(\"Max F1 for SVM for validation:\", svm_f1_valid)\n",
    "print(\"seen at parameter:\",maxp_linear1)\n",
    "print(\"Max F1 for SVM for testing:\", svm_f1_test)\n",
    "print(\"seen at parameter:\",maxp_linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max F1 for Naive Bayes for training: 0.8709333333333333\n",
      "seen at parameter: 0.1\n",
      "Max F1 for Naive Bayes for validation: 0.8436\n",
      "seen at parameter: 0.1\n",
      "Max F1 for Naive Bayes for testing: 0.83176\n",
      "seen at parameter: 0.1\n",
      "Max F1 for Decision Tree for training: 0.8117333333333333\n",
      "seen at parameter: 14\n",
      "Max F1 for Decision Tree for validation: 0.7226\n",
      "seen at parameter: 14\n",
      "Max F1 for Decision Tree for testing: 0.72664\n",
      "seen at parameter: 14\n",
      "Max F1 for SVM for training: 0.9632666666666667\n",
      "seen at parameter: 0.01\n",
      "Max F1 for SVM for validation: 0.8746\n",
      "seen at parameter: 0.01\n",
      "Max F1 for SVM for testing: 0.86924\n",
      "seen at parameter: 0.01\n"
     ]
    }
   ],
   "source": [
    "#maxp_dt1=14\n",
    "####### Training, validation and test F1-measure \n",
    "# IMDB BBOW\n",
    "# Naive bayes F1 using best parameter = 0.1\n",
    "nb_f1_train = f1_score(IMDB_train[1], naivebayes(IMDBt, IMDB_train[1], maxp_nb1, IMDBt),average='micro')\n",
    "gb_f1_train = f1_score(IMDB_train[1], naivegaus(IMDBt, IMDB_train[1], IMDBt), average=\"micro\")\n",
    "\n",
    "\n",
    "nb_f1_valid = f1_score(IMDB_valid[1], naivebayes(IMDBt, IMDB_train[1], maxp_nb1, IMDBv),average='micro')\n",
    "gb_f1_valid = f1_score(IMDB_valid[1], naivegaus(IMDBt, IMDB_train[1], IMDBv), average=\"micro\")\n",
    "\n",
    "nb_f1_test = f1_score(IMDB_test[1], naivebayes(IMDBt, IMDB_train[1], maxp_nb1, IMDBtest),average='micro')\n",
    "gb_f1_test = f1_score(IMDB_test[1], naivegaus(IMDBt, IMDB_train[1], IMDBtest), average=\"micro\")\n",
    "\n",
    "\n",
    "dt_f1_train=f1_score(IMDB_train[1], decisiontree_maxd(IMDBt, IMDB_train[1],  maxp_dt1, IMDBt), average='micro')\n",
    "dt_f1_valid=f1_score(IMDB_valid[1], decisiontree_maxd(IMDBt, IMDB_train[1],  maxp_dt1, IMDBv), average='micro')\n",
    "dt_f1_test=f1_score(IMDB_test[1], decisiontree_maxd(IMDBt, IMDB_train[1],  maxp_dt1, IMDBtest), average='micro')\n",
    "\n",
    "svm_f1_train=f1_score(IMDB_train[1], linearIMDB(IMDBt, IMDB_train[1], maxp_linear1, IMDBt),average='micro')\n",
    "svm_f1_valid=f1_score(IMDB_valid[1], linearIMDB(IMDBt, IMDB_train[1], maxp_linear1, IMDBv),average='micro')\n",
    "svm_f1_test=f1_score(IMDB_test[1], linearIMDB(IMDBt, IMDB_train[1], maxp_linear1, IMDBtest),average='micro')\n",
    "\n",
    "print(\"Max F1 for Naive Bayes for training:\", nb_f1_train)\n",
    "print(\"seen at parameter:\", maxp_nb1)\n",
    "#print(\"Max F1 for Gaussian Bayes for training:\", gb_f1_train)\n",
    "print(\"Max F1 for Naive Bayes for validation:\", nb_f1_valid)\n",
    "print(\"seen at parameter:\", maxp_nb1)\n",
    "#print(\"Max F1 for Gaussian Bayes for validation:\", gb_f1_valid)\n",
    "print(\"Max F1 for Naive Bayes for testing:\", nb_f1_test)\n",
    "print(\"seen at parameter:\", maxp_nb1)\n",
    "#print(\"Max F1 for Gaussian Bayes for testing:\", gb_f1_test)\n",
    "\n",
    "print(\"Max F1 for Decision Tree for training:\", dt_f1_train)\n",
    "print(\"seen at parameter:\",maxp_dt1)\n",
    "print(\"Max F1 for Decision Tree for validation:\", dt_f1_valid)\n",
    "print(\"seen at parameter:\",maxp_dt1)\n",
    "print(\"Max F1 for Decision Tree for testing:\", dt_f1_test)\n",
    "print(\"seen at parameter:\",maxp_dt1)\n",
    "\n",
    "print(\"Max F1 for SVM for training:\", svm_f1_train)\n",
    "print(\"seen at parameter:\",maxp_linear1)\n",
    "print(\"Max F1 for SVM for validation:\", svm_f1_valid)\n",
    "print(\"seen at parameter:\",maxp_linear1)\n",
    "print(\"Max F1 for SVM for testing:\", svm_f1_test)\n",
    "print(\"seen at parameter:\",maxp_linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "parameters_lin = [0.0001, 0.001, 0.01, 0.1, 1, 2, 10, 20,100, 1000]\n",
    "maxf1_linear_fbow, maxp_linear_fbow = testinglinearIMDB(IMDB_valid, IMDBt_fbow, IMDB_train, parameters_lin, IMDBv_fbow)\n",
    "print(\"Max F1 for Linear:\",maxf1_linear_fbow)\n",
    "print(\"seen at parameter:\", maxp_linear_fbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter: 0\n",
      "x 0.8415\n",
      "parameter: 0.0001\n",
      "x 0.8424000000000001\n",
      "parameter: 0.001\n",
      "x 0.8427\n",
      "parameter: 0.01\n",
      "x 0.8431000000000001\n",
      "parameter: 0.1\n",
      "x 0.8436\n",
      "parameter: 1\n",
      "x 0.8424000000000001\n",
      "parameter: 2\n",
      "x 0.8416999999999999\n",
      "parameter: 10\n",
      "x 0.8378\n",
      "parameter: 12\n",
      "x 0.8378\n",
      "parameter: 20\n",
      "x 0.8359\n",
      "parameter: 50\n",
      "x 0.8248999999999999\n",
      "Max F1 for Naive Bayes: 0.8436\n",
      "seen at parameter: 0.1\n",
      "parameter: 1.0\n",
      "x 0.6118\n",
      "parameter: 2.0\n",
      "x 0.6469\n",
      "parameter: 3.0\n",
      "x 0.6675\n",
      "parameter: 4.0\n",
      "x 0.6827\n",
      "parameter: 5.0\n",
      "x 0.6853\n",
      "parameter: 6.0\n",
      "x 0.6895\n",
      "parameter: 7.0\n",
      "x 0.6944\n",
      "parameter: 8.0\n",
      "x 0.7036\n",
      "parameter: 9.0\n",
      "x 0.7106\n",
      "parameter: 10.0\n",
      "x 0.7142\n",
      "parameter: 11.0\n",
      "x 0.7198\n",
      "parameter: 12.0\n",
      "x 0.7183\n",
      "parameter: 13.0\n",
      "x 0.7221\n",
      "parameter: 14.0\n",
      "x 0.7195\n",
      "parameter: 15.0\n",
      "x 0.7158999999999999\n",
      "parameter: 16.0\n",
      "x 0.7144\n",
      "parameter: 17.0\n",
      "x 0.7130999999999998\n",
      "parameter: 18.0\n",
      "x 0.7164\n",
      "parameter: 19.0\n",
      "x 0.7145\n",
      "parameter: 20.0\n",
      "x 0.7133\n",
      "parameter: 21.0\n",
      "x 0.7168\n",
      "parameter: 22.0\n",
      "x 0.7154\n",
      "parameter: 23.0\n",
      "x 0.7123\n",
      "parameter: 24.0\n",
      "x 0.7152\n",
      "parameter: 25.0\n",
      "x 0.7110000000000001\n",
      "parameter: 26.0\n",
      "x 0.7061\n",
      "parameter: 27.0\n",
      "x 0.7118\n",
      "parameter: 28.0\n",
      "x 0.7074\n",
      "parameter: 29.0\n",
      "x 0.7048\n",
      "parameter: 30.0\n",
      "x 0.7024\n",
      "parameter: 31.0\n",
      "x 0.7045\n",
      "parameter: 32.0\n",
      "x 0.706\n",
      "Max F1 for DecisionTree: 0.42999999999999994\n",
      "seen at parameter: 10.0\n",
      "linear parameter: 0.0001\n",
      "x 0.6437\n",
      "linear parameter: 0.001\n",
      "x 0.6598\n",
      "linear parameter: 0.01\n",
      "x 0.6655\n",
      "linear parameter: 0.1\n",
      "x 0.6964\n",
      "linear parameter: 1\n",
      "x 0.7774\n",
      "linear parameter: 2\n",
      "x 0.8068000000000001\n",
      "linear parameter: 10\n",
      "x 0.8527\n",
      "linear parameter: 20\n",
      "x 0.8652\n",
      "linear parameter: 100\n",
      "x 0.8778\n",
      "linear parameter: 1000\n",
      "x 0.8713999999999998\n",
      "Max F1 for Linear: 0.8778\n",
      "seen at parameter: 100\n"
     ]
    }
   ],
   "source": [
    "##### PARAMETER TUNING FOR IMDB_FBOW NAIVE BAYES, DECISION TREE, LINEAR SVM\n",
    "parameters = [0, 0.0001, 0.001, 0.01, 0.1, 1, 2, 10, 12, 20, 50]\n",
    "maxf1_nb_fbow, maxp_nb_fbow = testingnb(IMDB_valid, IMDBt_fbow, IMDB_train, parameters, IMDBv_fbow)\n",
    "print(\"Max F1 for Naive Bayes:\",maxf1_nb_fbow)\n",
    "print(\"seen at parameter:\", maxp_nb_fbow)\n",
    "\n",
    "maxf1_dt, maxp_dt = testingdt(IMDB_valid, IMDBt_fbow, IMDB_train, maxdepths, IMDBv_fbow)\n",
    "print(\"Max F1 for DecisionTree:\",maxf1_dt_fbow)\n",
    "print(\"seen at parameter:\", maxp_dt_fbow)\n",
    "\n",
    "parameters_lin = [0.0001, 0.001, 0.01, 0.1, 1, 2, 10, 20,100, 1000]\n",
    "maxf1_linear_fbow, maxp_linear_fbow = testinglinearIMDB(IMDB_valid, IMDBt_fbow, IMDB_train, parameters_lin, IMDBv_fbow)\n",
    "print(\"Max F1 for Linear:\",maxf1_linear_fbow)\n",
    "print(\"seen at parameter:\", maxp_linear_fbow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max F1 for SVM for training: 0.938\n",
      "seen at parameter: 100\n",
      "Max F1 for SVM for validation: 0.8778\n",
      "seen at parameter: 100\n",
      "Max F1 for SVM for testing: 0.87416\n",
      "seen at parameter: 100\n"
     ]
    }
   ],
   "source": [
    "svm_f1_train_fbow=f1_score(IMDB_train[1], linearIMDB(IMDBt_fbow, IMDB_train[1], maxp_linear_fbow, IMDBt_fbow),average='micro')\n",
    "svm_f1_valid_fbow=f1_score(IMDB_valid[1], linearIMDB(IMDBt_fbow, IMDB_train[1], maxp_linear_fbow, IMDBv_fbow),average='micro')\n",
    "svm_f1_test_fbow=f1_score(IMDB_test[1], linearIMDB(IMDBt_fbow, IMDB_train[1], maxp_linear_fbow, IMDBtest_fbow),average='micro')\n",
    "print(\"Max F1 for SVM for training:\", svm_f1_train_fbow)\n",
    "print(\"seen at parameter:\", maxp_linear_fbow)\n",
    "print(\"Max F1 for SVM for validation:\", svm_f1_valid_fbow)\n",
    "print(\"seen at parameter:\",maxp_linear_fbow)\n",
    "print(\"Max F1 for SVM for testing:\", svm_f1_test_fbow)\n",
    "print(\"seen at parameter:\",maxp_linear_fbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max F1 for Gaussian Bayes for training: 0.8617333333333334\n",
      "Max F1 for Gaussian Bayes for validation: 0.7508000000000001\n",
      "Max F1 for Gaussian Bayes for testing: 0.68908\n",
      "Max F1 for Decision Tree for training: 0.7662666666666667\n",
      "seen at parameter: 10.0\n",
      "Max F1 for Decision Tree for validation: 0.7141\n",
      "seen at parameter: 10.0\n",
      "Max F1 for Decision Tree for testing: 0.71024\n",
      "seen at parameter: 10.0\n",
      "Max F1 for SVM for training: 0.938\n",
      "seen at parameter: 100\n",
      "Max F1 for SVM for validation: 0.8778\n",
      "seen at parameter: 100\n",
      "Max F1 for SVM for testing: 0.87416\n",
      "seen at parameter: 100\n"
     ]
    }
   ],
   "source": [
    "#maxp_linear_fbow=100\n",
    "###### F1 FOR FBOW IMDB\n",
    "####### Training, validation and test F1-measure \n",
    "# Naive bayes F1 using best parameter = 0.1\n",
    "nb_f1_train_fbow = f1_score(IMDB_train[1], naivebayes(IMDBt_fbow, IMDB_train[1], maxp_nb_fbow, IMDBt_fbow),average='micro')\n",
    "gb_f1_train_fbow = f1_score(IMDB_train[1], naivegaus(IMDBt_fbow, IMDB_train[1], IMDBt_fbow), average=\"micro\")\n",
    "\n",
    "\n",
    "nb_f1_valid_fbow = f1_score(IMDB_valid[1], naivebayes(IMDBt_fbow, IMDB_train[1], maxp_nb_fbow, IMDBv_fbow),average='micro')\n",
    "gb_f1_valid_fbow = f1_score(IMDB_valid[1], naivegaus(IMDBt_fbow, IMDB_train[1], IMDBv_fbow), average=\"micro\")\n",
    "\n",
    "nb_f1_test_fbow = f1_score(IMDB_test[1], naivebayes(IMDBt_fbow, IMDB_train[1], maxp_nb_fbow, IMDBtest_fbow),average='micro')\n",
    "gb_f1_test_fbow = f1_score(IMDB_test[1], naivegaus(IMDBt_fbow, IMDB_train[1], IMDBtest_fbow), average=\"micro\")\n",
    "\n",
    "\n",
    "dt_f1_train_fbow=f1_score(IMDB_train[1], decisiontree_maxd(IMDBt_fbow, IMDB_train[1], maxp_dt_fbow, IMDBt_fbow), average='micro')\n",
    "dt_f1_valid_fbow=f1_score(IMDB_valid[1], decisiontree_maxd(IMDBt_fbow, IMDB_train[1], maxp_dt_fbow, IMDBv_fbow), average='micro')\n",
    "dt_f1_test_fbow=f1_score(IMDB_test[1], decisiontree_maxd(IMDBt_fbow, IMDB_train[1], maxp_dt_fbow, IMDBtest_fbow), average='micro')\n",
    "\n",
    "svm_f1_train_fbow=f1_score(IMDB_train[1], linearIMDB(IMDBt_fbow, IMDB_train[1], maxp_linear_fbow, IMDBt_fbow),average='micro')\n",
    "svm_f1_valid_fbow=f1_score(IMDB_valid[1], linearIMDB(IMDBt_fbow, IMDB_train[1], maxp_linear_fbow, IMDBv_fbow),average='micro')\n",
    "svm_f1_test_fbow=f1_score(IMDB_test[1], linearIMDB(IMDBt_fbow, IMDB_train[1], maxp_linear_fbow, IMDBtest_fbow),average='micro')\n",
    "\n",
    "#print(\"Max F1 for Naive Bayes for training:\", nb_f1_train_fbow)\n",
    "#print(\"seen at parameter:\", maxp_nb_fbow)\n",
    "print(\"Max F1 for Gaussian Bayes for training:\", gb_f1_train_fbow)\n",
    "#print(\"Max F1 for Naive Bayes for validation:\", nb_f1_valid_fbow)\n",
    "#print(\"seen at parameter:\", maxp_nb_fbow)\n",
    "print(\"Max F1 for Gaussian Bayes for validation:\", gb_f1_valid_fbow)\n",
    "#print(\"Max F1 for Naive Bayes for testing:\", nb_f1_test_fbow)\n",
    "#print(\"seen at parameter:\", maxp_nb_fbow)\n",
    "print(\"Max F1 for Gaussian Bayes for testing:\", gb_f1_test_fbow)\n",
    "\n",
    "print(\"Max F1 for Decision Tree for training:\", dt_f1_train_fbow)\n",
    "print(\"seen at parameter:\",maxp_dt_fbow)\n",
    "print(\"Max F1 for Decision Tree for validation:\", dt_f1_valid_fbow)\n",
    "print(\"seen at parameter:\",maxp_dt_fbow)\n",
    "print(\"Max F1 for Decision Tree for testing:\", dt_f1_test_fbow)\n",
    "print(\"seen at parameter:\",maxp_dt_fbow)\n",
    "\n",
    "print(\"Max F1 for SVM for training:\", svm_f1_train_fbow)\n",
    "print(\"seen at parameter:\", maxp_linear_fbow)\n",
    "print(\"Max F1 for SVM for validation:\", svm_f1_valid_fbow)\n",
    "print(\"seen at parameter:\",maxp_linear_fbow)\n",
    "print(\"Max F1 for SVM for testing:\", svm_f1_test_fbow)\n",
    "print(\"seen at parameter:\",maxp_linear_fbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
